mtcars$am <- as.factor(mt.cars$am)
mtcars$am <- as.factor(mtcars$am)
head(mtcars)
g <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am))
g
g <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight")
g
g <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight") + labs(legend = "Transmission")
g
?labs
g <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight") + labs(colours = "Transmission")
g
g <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight", colours="Transmission") + labs(colours = "Transmission")
g
g <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight")
g + scale_colour_discrete(name="Transmission")
g4 <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight") + scale_colour_discrete(name="Transmission")
g3 <- ggplot(mtcars,aes(mpg, cyl)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight") + scale_colour_discrete(name="Transmission")
g2 <- ggplot(mtcars,aes(mpg, hp)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Horsepower") + scale_colour_discrete(name="Transmission")
g3 <- ggplot(mtcars,aes(mpg, cyl)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Cylinders") + scale_colour_discrete(name="Transmission")
g1 <- ggplot(mtcars,aes(mpg, am)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Transmission") + scale_colour_discrete(name="Transmission")
library(gridExtra)
grid.arrange(g1,g2,g3,g4)
g4 <- ggplot(mtcars,aes(mpg, wt)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Weight") + scale_colour_discrete(name="Transmission") + theme(legend.position="none")
g1 <- ggplot(mtcars,aes(mpg, am)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Transmission") + scale_colour_discrete(name="Transmission") + theme(legend.position="none")
g2 <- ggplot(mtcars,aes(mpg, hp)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Horsepower") + scale_colour_discrete(name="Transmission") + theme(legend.position="none")
g3 <- ggplot(mtcars,aes(mpg, cyl)) + geom_point(aes(color=am)) + labs(x = "Miles per Gallon", y = "Cylinders") + scale_colour_discrete(name="Transmission") + theme(legend.position="none")
grid.arrange(g1,g2,g3, g4)
?mtcars
fit1 <- lm(mpg ~ am, data=mtcars)
summary(fit1)
plot(fit1)
fit2 <- lm(mpg ~ am + cyl + hp, data=mtcars)
summary(fit2)
fit3 <- glm(mpg~am+cyl+hp, data=mtcars, family=binomial)
summary(fit3)
fit1 <- lm(mpg ~ am, data=mtcars)
fit2 <- lm(mpg ~ am + cyl, data=mtcars)
fit3 <- lm(mpg ~ am + cyl + hp,data=mtcars)
anova(fit1, fit2, fit3)
summary(fit3)
fit4 <- lm(mpg ~ am + cyl + hp + wt,data=mtcars)
anova(fit1, fit2, fit3, fit4)
shapiro.test(fit4)
shapiro.test(fit4$residuals)
shapiro.test(fit3$residuals)
shapiro.test(fit2$residuals)
shapiro.test(fit1$residuals)
summary(fit4)
par(mfrow=2)
par(mfrow=c(2,2))
plot(fit4)
par(mfrow=c(2,1))
plot(density(resid(fit4)))
qqnorm(resid(fit4))
plot(density(resid(fit4))
)
plot(density(resid(fit4)))
par(mfrow=c(1,1))
plot(density(resid(fit4)))
qqnorm(resid(fit4))
plot(fit4)
plot(fit4)
?anova
anova(fit1,fit2,fit3,fit4)$coeff
anova(fit1,fit2,fit3,fit4)$p
anova(fit1,fit2,fit3,fit4)
anova(fit1,fit2,fit3,fit4)$Pr
?boxplot
boxplot(mpg~am,data=mtcars)
boxplot(mpg~am,data=mtcars, col=am)
boxplot(mpg~am,data=mtcars, col=aes(am)
)
boxplot(mpg~am,data=mtcars,fill=am
)
boxplot(mpg~am,data=mtcars,fill=c(blue,green)
)
boxplot(mpg~am,data=mtcars,fill=c("blue","green"))
boxplot(mpg~am,data=mtcars,col=c("blue","green"))
boxplot(mpg~am,data=mtcars,col=c("cyan","orange"))
boxplot(mpg~am,data=mtcars,col=c("orange","cyan"))
boxplot(mpg~am,data=mtcars,col=c("orange","cyan"), xlab="Transmission",ylab="Miles per Gallon")
fit5 ~ lm(mpg~.,data=mtcars)
fit5 -> lm(mpg~.,data=mtcars)
fit5 <- lm(mpg~.,data=mtcars)
anova(fit1,fit2,fit3,fit4,fit5)
summary(fit4)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
download.packages(AppliedPredictiveModelin)
download.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("Caret")
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
qplot(training$CompressiveStrength)
plot(training$CompressiveStrength)
plot(CompressiveStrength, colors = Cement, data=training)
plot(training$CompressiveStrength, colors = training$Cement)
plot(training$CompressiveStrength, color = training$Cement)
plot(training$CompressiveStrength, color = training$Cement)
library(ggplot2)
warnings()
geom_dotplot(training&CompressiveStrength)
geom_dotplot(training$CompressiveStrength)
plot(training$CompressiveStrength, color = training$Cement)
plot(training$CompressiveStrength, col = training$Cement)
warnings()
plot(training$CompressiveStrength, col=training$Cement)
plot(training$CompressiveStrength, col=as.integer(training$Cement)
)
plot(training$CompressiveStrength, col=as.integer(training$Cement))
g <- ggplot(training, aes(CompressiveStrengt))
g + geom_point()
g <- ggplot(training, aes(CompressiveStrength))
g <- ggplot(training, aes(CompressiveStrength))
g + geom_point()
g <- ggplot(training, aes(CompressiveStrength, row.names(training)))
g + geom_point()
g <- ggplot(training, aes(row.names(training), CompressiveStrength))
g + geom_point()
g + geom_point() + geom_color(Cement)
g <- ggplot(training, aes(row.names(training), CompressiveStrength), colour=Cement)
g + geom_point()
head(training)
g <- ggplot(training, aes(row.names(training), CompressiveStrength colours=Cement)
g <- ggplot(training, aes(row.names(training), CompressiveStrength, colours=Cement))
g + geom_point()
g + geom_point() + colScale
g + geom_point() + scale_colour_gradientn()
?scale_color_gradientn
g + geom_point() + scale_colour_gradient2()
g + geom_point() + scale_colour_gradient2()
library(Hmisc)
install.packages("Hmisc")
library("Hmisc")
library(Hmisc)
?cut2
library(HMISC)
library(Hmisc)
install.packages("Hmisc")
install.packages("Hmisc")
install.packages("Hmisc")
head(training)
?cut2
cut2(training$Cement, g=3)
library(Hmisc)
libarry(ggplot2)
library(ggplot2)
library(Hmisc)
library(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
library(ggplot2)
library(Hmisc)
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
g <- ggplot(x = row.names(training), y = training$CompressiveStrength)
g + geom_point()
g + geom_point()
g <- ggplot(trainig, aes(x = row.names(training), y = CompressiveStrength)
)
g <- ggplot(training, aes(x = row.names(training), y = CompressiveStrength))
g + geom_point()
cut2(training$Cement, g=3)
g <- ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(Cement, g =3)))
g + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(Cement, g =3))) + geom_point()
head(training)
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(BlastFurnaceSlag, g =3))) + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(FlyAsh, g =3))) + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(Age, g =3))) + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(Water, g =3))) + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(CoarseAggregate, g =3))) + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(FineAggregate, g =3))) + geom_point()
ggplot(training, aes(x = row.names(training), y = CompressiveStrength, col = cut2(Superplasticizer, g =3))) + geom_point()
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(training, aes(x=Superplasticizer)) + geom_hist()
ggplot(training, aes(x=Superplasticizer)) + geom_histogram()
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.9)
preProc
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
training <- subset(segmentationOriginal, Case = "train")
head(training)
training <- subset(segmentationOriginal, segmentationOriginal$Case = "Train")
training <- subset(segmentationOriginal, Case == "Train")
head(training)
testing <- subset(segmentationOriginal, Case == "Test")
dim(training)
dim(testing)
set.seed(125)
model <- rpart(Class ~ ., data=training,method="class")
library(rpart)
model <- rpart(Class ~ ., data=training,method="class")
print(model)
model<-train(Class ~ .,
data = training,
method = "rpart")
model<-train(Class ~ .,data = training,method = "rpart")
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
dim(training)
model<-train(Class ~ .,data = training,method = "rpart")
library(caret)
model<-train(Class ~ .,data = training,method = "rpart")
print(model)
library(rattle)
install.packages(rattle)
install.packages("rattle")
fanceRpartPlot(model)
fancyRpartPlot(model)
library(rattle)
fancyRpartPlot(model)
library(rattle)
fancyRpartPlot(model)
dim(training)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training <- subset(segmentationOriginal, Case = "Train")
dim(training)
training <- subset(segmentationOriginal, Case = "train")
dim(training)
training <- subset(segmentationOriginal, Case == "train")
dim(training)
training <- subset(segmentationOriginal, Case == "Train")
dim(training)
model <- train(Class ~ .,data=training, method="rpart")
library(rattle)
fancyRpartPlot(model)
plot(model$finalModel, uniform = TRUE)
text(model$finalModel,use.n=TRUE,all=TRUE,cex=8.)
plot(model$finalModel, uniform = TRUE)
text(model$finalModel,use.n=TRUE,all=TRUE,cex=.8)
library(pgmm)
install.packages("pgmm")
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
dim(olive)
?tree
newdata = as.data.frame(t(colMeans(olive)))
head(newdata)
model <- train(Area ~ ., method="tree",data=olive)
install.packages("tree")
library(tree)
model <- train(Area ~ ., method="tree",data=olive)
model <- train(Area ~ ., method="rpart",data=olive)
predict(mode, newdata)
predict(model, newdata)
head(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
head(trainSA)
train <- trainSA[, !(colnames(trainSA) %in% c("sbp","adiposity","famhist"))]
head(train)
model <- train(chd ~ ., data=train, family="binominal", method="glm")
model <- train(chd ~ ., data=train, family="binomial", method="glm")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(train$chd, predict(model, train))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
train(y ~ ., data=vowel.train,method="rf",prox=TRUE)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
m1 <- train(y~., data=vowel.train,method="rf",prox=TRUE)
library(caret)
m1 <- train(y~., data=vowel.train,method="rf",prox=TRUE)
m2 <- train(y~., data=vowel.train,method="gbm",verbose=FALSE)
predict(m1, newdata = vowel.test)
head(vowel.test)
predm1 <- predict(m1, newdata = vowel.test)
predm2 <- predict(m2, newdata = vowel.test)
confusionmatrix(vowel.test$y,predm1)
confusionMatrix(vowel.test$y,predm1)
confusionMatrix(vowel.test$y,predm2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.set(62433)
set.seed(62433)
rf <- train(diagnosis ~ ., data=training, method="rf")
gbm <- train(diagnosis ~ .,data=training,method="gbm")
lda <- train(diagnosis ~ .,data=training,method="lda")
lda
predrf <- predict(rf, newdata = testing)
predgbm <- predict(gbm, newdata = testing)
predlda <- predict(lda, newdata = testing)
head(predrf)
new <- array(testing$diagnosis,predrf,predgbm,predlda)
predlda
new <- matrix(training$diagnosis, predrf)
new <- matrix(training$diagnosis)
new <- cbind(training$diagnosis,predrf,predgbm,predlda)
head(new)
rf2 <- train(diagnosis ~ ., data=new, method="rf")
rf2 <- train(V1 ~ ., data=new, method="rf")
dim(new)
tail(new)
colnames(new) <- c("Diagnosis", "P1", "P2", "P3")
head(new)
rf2 <- train(Diagnosis ~ ., data=new, method="rf")
p <- predict(rf2, newdata = testing)
p <- predict(rf2, newdata = new)
confusionMatrix(new$Diagnosis, p)
head(new)
confusionMatrix(new$Diagnosis, p)
p <- predict(rf2, newdata = new)
confusionMatrix(predrf, testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
head(training)
m <- train(CompressiveStrength ~ ., data=training, method="lasso")
?plot.enet
plot.enet(m, xvar=penalty,use.color=TRUE)
plot.enet(m, xvar="penalty",use.color=TRUE)
m
plot.enet(m$finalModel, xvar="penalty",use.color=TRUE)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testin
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model <- train(CompressiveStrength ~ ., data=training, method="svm")
model <- svm(CompressiveStrength ~ ., data=training)
library(e1071)
model <- svm(CompressiveStrength ~ ., data=training)
pred <- predict(model, newdata=testing)
print(model)
accuracy(model, testing$CompressiveStrength)
?accuracy
library(forecast)
accuracy(pred, testing$CompressiveStrength)
library(plotly)
head(mtcars)
plot_ly(mtcars,mpg,cyl)
plot_ly(mtcars)
plot_ly(mtcars$cyl,type="histogram")
plot_ly(mtcars,type="histogram")
plot_ly(mtcars,x=mpg,y=cyl,mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcards$cyl,mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$cyl,mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=mtcars$cyl,mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers") %>% layout(xaxis = Miles per Gallon)
library(dply\)
library(dplyr)
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers") %>% layout(xaxis = Miles per Gallon)
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers") %>% layout(xaxis = "Miles per Gallon")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers")
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers") %>% layout(xaxis = list(title = "Miles per Gallon"))
plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers") %>% layout(xaxis = list(title = "Miles per Gallon"), yaxis = list(title = "Horsepower"))
install.packages("webshot")
p = plot_ly(mtcars,x=mtcars$mpg,y=mtcars$hp,color=as.factor(mtcars$cyl),mode="markers") %>% layout(xaxis = list(title = "Miles per Gallon"), yaxis = list(title = "Horsepower"))
p
?plot_ly
dpois(1,3)
qpois(1,3)
ppois(1,3)
ppois(1,3)
pgamma(1,2,1/3)
pgamma(1.5,2,1/3)-pgamma(0.5,2,1/3)
qnorm(0.95,0,1)
qnorm(0.95,1,0)
qnorm(0.95,0,1)
?qnorm
qnorm(0.975,0,1)
qnorm(.95,0,1)
qnorm(.90,0,1)
pnorm(.95,0,1)
pnorm(.975,0,1)
qnorm
?qnorm
qnorm(.975)
plot(theta,dbeta(theta,1,5),type="l")
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,1,5),type="l")
pbeta(.5,1,6)
qbeta(.975,16,8)
pbeta(.35,16,8)
pbeta(.35,21,8)
qbeta(.975,8,16)
pbeta(.35,8,16)
pbeta(.35,8,21)
qgamma(.05,67,6)
qbeta(.1,5,81.5)
30+16+8+114+60+4+23+30+105
qbeta(.975,9,390)
qnorm(.975,95.41,0.25)
z <- rgamma(n=1000, shape=3, rate=200)
x <- 1/z
mean(x)
z <- rgamma(1000, shape=16.5, rate=6022.9)
sig2 <- 1/z
mu <- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))
quantile(x=mu, probs=c(0.025, 0.975))
qnorm(.975,96.17,sqrt(24))
qnorm(.975,95.41,sqrt(24))
qnorm(.975,95.41,0.042)
read.table(url="http://www.stat.ufl.edu/~winner/data/pgalpga2008.dat")
read.table("http://www.stat.ufl.edu/~winner/data/pgalpga2008.dat")
a <- read.table("http://www.stat.ufl.edu/~winner/data/pgalpga2008.dat")
head(a)
datF <- subset(a, FM==1, select=1:2)
datF <- subset(a, VR==1, select=1:2)
datF <- subset(a, V3==1, select=1:2)
head(datF)
head(a)
plot(a)
plot(a)
plot(datF)
plot(datF)
pair(a)
pairs(a)
lm(V1 ~ V2, data=datF)
lm(V2 ~ V1, data=datF)
130.8933 - 0.2565 * 260
l <- lm(V2 ~ V1, data=datF)
predit(l,data.frame(T=31), interval="predict")
predict(l,data.frame(T=31), interval="predict")
l
summary(l)
130.8933 - 0.2565 * qt(.975,155)
setwd("C:/Users/Markus/Code/WordPredictor/reports")
shiny::runApp('C:/Users/Markus/Code/WordPredictor')
setwd("C:/Users/Markus/Code/WordPredictor")
